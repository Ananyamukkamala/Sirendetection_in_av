{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import joblib\n",
        "\n",
        "# Load the dataset from CSV files\n",
        "ambulance_file_path = 'ambulance.csv'\n",
        "traffic_file_path = 'traffic.csv'\n",
        "\n",
        "ambulance_data = pd.read_csv(ambulance_file_path)\n",
        "traffic_data = pd.read_csv(traffic_file_path)\n",
        "\n",
        "# Combine the datasets\n",
        "dataset = pd.concat([ambulance_data, traffic_data], ignore_index=True)\n",
        "\n",
        "# Split the dataset into features and labels\n",
        "features = dataset.iloc[:, :-1].values\n",
        "labels = dataset.iloc[:, -1].values\n",
        "\n",
        "# Convert labels to numerical values\n",
        "label_encoder = LabelEncoder()\n",
        "labels_encoded = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    features, labels_encoded, test_size=0.27, random_state=48\n",
        ")\n",
        "\n",
        "# Define and train the classifier\n",
        "classifier = make_pipeline(StandardScaler(), SVC())\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the classifier\n",
        "y_pred = classifier.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "\n",
        "# Save the classifier model and label encoder\n",
        "classifier_model_path = 'classifier_model.pkl'\n",
        "label_encoder_path = 'label_encoder.pkl'\n",
        "\n",
        "joblib.dump(classifier, classifier_model_path)\n",
        "joblib.dump(label_encoder, label_encoder_path)\n",
        "\n",
        "print(\"Classifier model and label encoder saved successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4fS_8GeNV2-",
        "outputId": "91523562-5410-4e51-c987-aeb92b4cc60d"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9814814814814815\n",
            "Precision: 0.9820987654320987\n",
            "Recall: 0.9814814814814815\n",
            "F1 Score: 0.9814494536044173\n",
            "Classifier model and label encoder saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import joblib\n",
        "\n",
        "# Load the trained classifier and label encoder\n",
        "classifier = joblib.load('classifier_model.pkl')  # Replace with the path to your trained classifier model\n",
        "label_encoder = joblib.load('label_encoder.pkl')  # Replace with the path to your label encoder\n",
        "\n",
        "# Define a function to extract features from the WAV file\n",
        "def extract_features(file_path):\n",
        "    audio, sr = librosa.load(file_path, sr=None)  # Load the audio file\n",
        "\n",
        "    # Extract features\n",
        "    chroma_stft = librosa.feature.chroma_stft(audio, sr=sr)\n",
        "    spectral_centroid = librosa.feature.spectral_centroid(audio, sr=sr)[0]\n",
        "    spectral_bandwidth = librosa.feature.spectral_bandwidth(audio, sr=sr)[0]\n",
        "    spectral_rolloff = librosa.feature.spectral_rolloff(audio, sr=sr)[0]\n",
        "    rmse = librosa.feature.rms(audio)[0]\n",
        "    zero_crossing_rate = librosa.feature.zero_crossing_rate(audio)[0]\n",
        "\n",
        "    # Concatenate features into a single feature vector\n",
        "    features = np.hstack(\n",
        "        (chroma_stft, spectral_centroid.reshape(-1, 1), spectral_bandwidth.reshape(-1, 1),\n",
        "         spectral_rolloff.reshape(-1, 1), rmse.reshape(-1, 1), zero_crossing_rate.reshape(-1, 1))\n",
        "    )\n",
        "    return features\n",
        "\n",
        "# Define a function to classify a given WAV file\n",
        "def classify_audio(file_path):\n",
        "    features = extract_features(file_path)  # Extract features from the WAV file\n",
        "\n",
        "    # Scale the features using the same scaler used during training\n",
        "    scaler = StandardScaler()\n",
        "    scaled_features = scaler.fit_transform(features)\n",
        "\n",
        "    # Classify the audio sample\n",
        "    predicted_label = label_encoder.inverse_transform(classifier.predict(scaled_features))\n",
        "\n",
        "    return predicted_label[0]  # Return the predicted label as a string\n",
        "\n",
        "# Use the classify_audio function to classify a given WAV file\n",
        "wav_file_path = 'sound_1.wav'  # Replace with the path to your input WAV file\n",
        "\n",
        "predicted_label = classify_audio(wav_file_path)\n",
        "print(\"Predicted Label:\", predicted_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "WuMcsIahPN6H",
        "outputId": "7f18bc60-8ffb-4d36-f3b8-b87de3166f8c"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-6ebf03813d42>\u001b[0m in \u001b[0;36m<cell line: 45>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mwav_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'sound_1.wav'\u001b[0m  \u001b[0;31m# Replace with the path to your input WAV file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mpredicted_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassify_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predicted Label:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-65-6ebf03813d42>\u001b[0m in \u001b[0;36mclassify_audio\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Define a function to classify a given WAV file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mclassify_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Extract features from the WAV file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# Scale the features using the same scaler used during training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-65-6ebf03813d42>\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Extract features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mchroma_stft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchroma_stft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mspectral_centroid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspectral_centroid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mspectral_bandwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspectral_bandwidth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: chroma_stft() takes 0 positional arguments but 1 positional argument (and 1 keyword-only argument) were given"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import librosa\n",
        "from scipy.io import wavfile\n",
        "import joblib\n",
        "\n",
        "# Load the datasets\n",
        "ambulance_data = pd.read_csv('ambulance.csv')\n",
        "traffic_data = pd.read_csv('traffic.csv')\n",
        "\n",
        "# Combine the datasets\n",
        "combined_data = pd.concat([ambulance_data, traffic_data], ignore_index=True)\n",
        "\n",
        "# Separate features and labels\n",
        "features = combined_data.iloc[:, :-1]\n",
        "labels = combined_data.iloc[:, -1]\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, encoded_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train the classifier\n",
        "classifier = SVC()\n",
        "classifier.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = classifier.predict(X_test_scaled)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "\n",
        "# Save the classifier model and label encoder\n",
        "joblib.dump(classifier, 'classifier_model.pkl')\n",
        "joblib.dump(label_encoder, 'label_encoder.pkl')\n",
        "\n",
        "# Define a function to classify a single WAV file\n",
        "def classify_audio(file_path):\n",
        "    audio, sr = librosa.load(file_path, sr=None)  # Load the audio file\n",
        "\n",
        "    # Extract features\n",
        "    chroma_stft = librosa.feature.chroma_stft(y=audio, sr=sr)\n",
        "    spectral_centroid = librosa.feature.spectral_centroid(y=audio, sr=sr)[0]\n",
        "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=audio, sr=sr)[0]\n",
        "    spectral_rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sr)[0]\n",
        "    rmse = librosa.feature.rms(y=audio)[0]\n",
        "    zero_crossing_rate = librosa.feature.zero_crossing_rate(y=audio)[0]\n",
        "\n",
        "    # Concatenate features into a single feature vector\n",
        "    features = np.hstack(\n",
        "        (chroma_stft.T, spectral_centroid.reshape(-1, 1), spectral_bandwidth.reshape(-1, 1),\n",
        "         spectral_rolloff.reshape(-1, 1), rmse.reshape(-1, 1), zero_crossing_rate.reshape(-1, 1))\n",
        "    )\n",
        "\n",
        "    # Scale the features\n",
        "    scaled_features = scaler.transform(features)\n",
        "\n",
        "    # Classify the audio sample\n",
        "    predicted_label = label_encoder.inverse_transform(classifier.predict(scaled_features))\n",
        "\n",
        "    return predicted_label[0]  # Return the predicted label as a string\n",
        "\n",
        "# Use the classify_audio function to classify a single WAV file\n",
        "wav_file_path = 'sound_1.wav'  # Replace with the path to your input WAV file\n",
        "\n",
        "predicted_label = classify_audio(wav_file_path)\n",
        "print(\"Predicted Label:\", predicted_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "dmnbgdgAPdL3",
        "outputId": "b009d679-4e6b-4b06-a2c7-6af2019d8eb6"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.975\n",
            "Precision: 0.9722222222222222\n",
            "Recall: 0.9722222222222222\n",
            "F1 Score: 0.9722222222222222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-68-51bcfd0cdecb>\u001b[0m in \u001b[0;36m<cell line: 86>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0mwav_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'sound_1.wav'\u001b[0m  \u001b[0;31m# Replace with the path to your input WAV file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m \u001b[0mpredicted_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassify_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predicted Label:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-68-51bcfd0cdecb>\u001b[0m in \u001b[0;36mclassify_audio\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;31m# Scale the features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0mscaled_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;31m# Classify the audio sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m    990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m         \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 992\u001b[0;31m         X = self._validate_data(\n\u001b[0m\u001b[1;32m    993\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m             \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    390\u001b[0m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m                 \u001b[0;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: X has 17 features, but StandardScaler is expecting 6 features as input."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import librosa\n",
        "from scipy.io import wavfile\n",
        "import joblib\n",
        "\n",
        "# Load the datasets\n",
        "ambulance_data = pd.read_csv('ambulance.csv')\n",
        "traffic_data = pd.read_csv('traffic.csv')\n",
        "\n",
        "# Combine the datasets\n",
        "combined_data = pd.concat([ambulance_data, traffic_data], ignore_index=True)\n",
        "\n",
        "# Separate features and labels\n",
        "features = combined_data.iloc[:, :-1]\n",
        "labels = combined_data.iloc[:, -1]\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, encoded_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Select the relevant features for scaling\n",
        "selected_features = ['chroma_stft', 'spectral_centroid', 'spectral_bandwidth', 'spectral_rolloff', 'rmse', 'zero_crossing_rate']\n",
        "X_train_selected = X_train[selected_features]\n",
        "X_test_selected = X_test[selected_features]\n",
        "\n",
        "# Scale the selected features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_selected)\n",
        "X_test_scaled = scaler.transform(X_test_selected)\n",
        "\n",
        "# Train the classifier\n",
        "classifier = SVC()\n",
        "classifier.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = classifier.predict(X_test_scaled)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "\n",
        "# Save the classifier model and label encoder\n",
        "joblib.dump(classifier, 'classifier_model.pkl')\n",
        "joblib.dump(label_encoder, 'label_encoder.pkl')\n",
        "\n",
        "# Define a function to classify a single WAV file\n",
        "def classify_audio(file_path):\n",
        "    audio, sr = librosa.load(file_path, sr=None)  # Load the audio file\n",
        "\n",
        "    # Extract features\n",
        "    chroma_stft = librosa.feature.chroma_stft(y=audio, sr=sr)\n",
        "    spectral_centroid = librosa.feature.spectral_centroid(y=audio, sr=sr)[0]\n",
        "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=audio, sr=sr)[0]\n",
        "    spectral_rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sr)[0]\n",
        "    rmse = librosa.feature.rms(y=audio)[0]\n",
        "    zero_crossing_rate = librosa.feature.zero_crossing_rate(y=audio)[0]\n",
        "\n",
        "    # Concatenate features into a single feature vector\n",
        "    features = np.hstack(\n",
        "        (chroma_stft.T, spectral_centroid.reshape(-1, 1), spectral_bandwidth.reshape(-1, 1),\n",
        "         spectral_rolloff.reshape(-1, 1), rmse.reshape(-1, 1), zero_crossing_rate.reshape(-1, 1))\n",
        "    )\n",
        "\n",
        "    # Select the relevant features for scaling\n",
        "    selected_features = features[:, :6]\n",
        "\n",
        "    # Scale the selected features\n",
        "    scaled_features = scaler.transform(selected_features)\n",
        "\n",
        "    # Classify the audio sample\n",
        "    predicted_label = label_encoder.inverse_transform(classifier.predict(scaled_features))\n",
        "\n",
        "    return predicted_label[0]  # Return the predicted label as a string\n",
        "\n",
        "# Use the classify_audio function to classify a single WAV file\n",
        "wav_file_path = 'sound_403.wav'  # Replace with the path to your input WAV file\n",
        "\n",
        "predicted_label = classify_audio(wav_file_path)\n",
        "print(\"Predicted Label:\", predicted_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cBljQNSUTQ3",
        "outputId": "331870f9-3790-4ba5-970f-c6184cde2405"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.975\n",
            "Precision: 0.9722222222222222\n",
            "Recall: 0.9722222222222222\n",
            "F1 Score: 0.9722222222222222\n",
            "Predicted Label: ambulance\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import librosa\n",
        "from scipy.io import wavfile\n",
        "import joblib\n",
        "\n",
        "# Load the datasets\n",
        "ambulance_data = pd.read_csv('ambulance.csv')\n",
        "traffic_data = pd.read_csv('traffic.csv')\n",
        "\n",
        "# Combine the datasets\n",
        "combined_data = pd.concat([ambulance_data, traffic_data], ignore_index=True)\n",
        "\n",
        "# Separate features and labels\n",
        "features = combined_data.iloc[:, :-1]\n",
        "labels = combined_data.iloc[:, -1]\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, encoded_labels, test_size=0.2, random_state=25)\n",
        "\n",
        "# Select the relevant features for scaling\n",
        "selected_features = ['chroma_stft', 'spectral_centroid', 'spectral_bandwidth', 'spectral_rolloff', 'rmse', 'zero_crossing_rate']\n",
        "X_train_selected = X_train[selected_features]\n",
        "X_test_selected = X_test[selected_features]\n",
        "\n",
        "# Scale the selected features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_selected)\n",
        "X_test_scaled = scaler.transform(X_test_selected)\n",
        "\n",
        "# Train the classifier\n",
        "classifier = SVC()\n",
        "classifier.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = classifier.predict(X_test_scaled)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "\n",
        "# Save the classifier model and label encoder\n",
        "joblib.dump(classifier, 'classifier_model.pkl')\n",
        "joblib.dump(label_encoder, 'label_encoder.pkl')\n",
        "\n",
        "# Define a function to classify a single WAV file\n",
        "def classify_audio(file_path):\n",
        "    audio, sr = librosa.load(file_path, sr=None)  # Load the audio file\n",
        "\n",
        "    # Extract features\n",
        "    chroma_stft = librosa.feature.chroma_stft(y=audio, sr=sr)\n",
        "    spectral_centroid = librosa.feature.spectral_centroid(y=audio, sr=sr)[0]\n",
        "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=audio, sr=sr)[0]\n",
        "    spectral_rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sr)[0]\n",
        "    rmse = librosa.feature.rms(y=audio)[0]\n",
        "    zero_crossing_rate = librosa.feature.zero_crossing_rate(y=audio)[0]\n",
        "\n",
        "    # Concatenate features into a single feature vector\n",
        "    features = np.hstack(\n",
        "        (chroma_stft.T, spectral_centroid.reshape(-1, 1), spectral_bandwidth.reshape(-1, 1),\n",
        "         spectral_rolloff.reshape(-1, 1), rmse.reshape(-1, 1), zero_crossing_rate.reshape(-1, 1))\n",
        "    )\n",
        "\n",
        "    # Select the relevant features for scaling\n",
        "    selected_features = features[:, :6]\n",
        "\n",
        "    # Scale the selected features\n",
        "    scaled_features = scaler.transform(selected_features)\n",
        "\n",
        "    # Classify the audio sample\n",
        "    predicted_label = label_encoder.inverse_transform(classifier.predict(scaled_features))\n",
        "\n",
        "    return predicted_label[1]  # Return the predicted label as a string\n",
        "\n",
        "# Use the classify_audio function to classify a single WAV file\n",
        "wav_file_path = 'sound_1.wav'  # Replace with the path to your input WAV file\n",
        "\n",
        "predicted_label = classify_audio(wav_file_path)\n",
        "print(\"Predicted Label:\", predicted_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTh2kJ7gVOL1",
        "outputId": "d2918fef-47cb-48d0-8418-01d5c740246e"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9125\n",
            "Precision: 0.9024390243902439\n",
            "Recall: 0.925\n",
            "F1 Score: 0.9135802469135802\n",
            "Predicted Label: ambulance\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import librosa\n",
        "from scipy.io import wavfile\n",
        "import joblib\n",
        "\n",
        "# Load the datasets\n",
        "ambulance_data = pd.read_csv('ambulance.csv')\n",
        "traffic_data = pd.read_csv('traffic.csv')\n",
        "\n",
        "# Separate features and labels\n",
        "ambulance_features = ambulance_data.iloc[:, :-1]\n",
        "ambulance_labels = ambulance_data.iloc[:, -1]\n",
        "traffic_features = traffic_data.iloc[:, :-1]\n",
        "traffic_labels = traffic_data.iloc[:, -1]\n",
        "\n",
        "# Encode labels separately for ambulance and traffic datasets\n",
        "ambulance_label_encoder = LabelEncoder()\n",
        "ambulance_encoded_labels = ambulance_label_encoder.fit_transform(ambulance_labels)\n",
        "traffic_label_encoder = LabelEncoder()\n",
        "traffic_encoded_labels = traffic_label_encoder.fit_transform(traffic_labels)\n",
        "\n",
        "# Combine the encoded labels and features\n",
        "combined_features = pd.concat([ambulance_features, traffic_features], ignore_index=True)\n",
        "combined_encoded_labels = np.concatenate([ambulance_encoded_labels, traffic_encoded_labels])\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(combined_features, combined_encoded_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train the classifier\n",
        "classifier = SVC()\n",
        "classifier.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = classifier.predict(X_test_scaled)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "\n",
        "# Save the classifier model and label encoders\n",
        "joblib.dump(classifier, 'classifier_model.pkl')\n",
        "joblib.dump(ambulance_label_encoder, 'ambulance_label_encoder.pkl')\n",
        "joblib.dump(traffic_label_encoder, 'traffic_label_encoder.pkl')\n",
        "\n",
        "# Define a function to classify a single WAV file\n",
        "def classify_audio(file_path):\n",
        "    audio, sr = librosa.load(file_path, sr=None)  # Load the audio file\n",
        "\n",
        "    # Extract features\n",
        "    chroma_stft = librosa.feature.chroma_stft(y=audio, sr=sr)\n",
        "    spectral_centroid = librosa.feature.spectral_centroid(y=audio, sr=sr)[0]\n",
        "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=audio, sr=sr)[0]\n",
        "    spectral_rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sr)[0]\n",
        "    rmse = librosa.feature.rms(y=audio)[0]\n",
        "    zero_crossing_rate = librosa.feature.zero_crossing_rate(y=audio)[0]\n",
        "\n",
        "    # Concatenate features into a single feature vector\n",
        "    features = np.hstack(\n",
        "        (chroma_stft.T, spectral_centroid.reshape(-1, 1), spectral_bandwidth.reshape(-1, 1),\n",
        "         spectral_rolloff.reshape(-1, 1), rmse.reshape(-1, 1), zero_crossing_rate.reshape(-1, 1))\n",
        "    )\n",
        "\n",
        "    # Scale the features\n",
        "    scaled_features = scaler.transform(features)\n",
        "\n",
        "    # Classify the audio sample\n",
        "    predicted_label = classifier.predict(scaled_features)\n",
        "\n",
        "    return predicted_label[0]  # Return the predicted label as a string\n",
        "\n",
        "# Use the classify_audio function to classify a single WAV file\n",
        "wav_file_path = 'sound_403.wav'  # Replace with the path to your input WAV file\n",
        "\n",
        "predicted_label = classify_audio(wav_file_path)\n",
        "\n",
        "# Load the label encoders\n",
        "ambulance_label_encoder = joblib.load('ambulance_label_encoder.pkl')\n",
        "traffic_label_encoder = joblib.load('traffic_label_encoder.pkl')\n",
        "\n",
        "# Map the predicted label back to the original class name\n",
        "if predicted_label == ambulance_label_encoder.transform(['ambulance']):\n",
        "    predicted_label = 'ambulance'\n",
        "elif predicted_label == traffic_label_encoder.transform(['traffic']):\n",
        "    predicted_label = 'traffic'\n",
        "\n",
        "print(\"Predicted Label:\", predicted_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "8P_0YHFJV2kw",
        "outputId": "2466bf56-442c-461d-feb4-b19da6243b3e"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-6abefeb652d2>\u001b[0m in \u001b[0;36m<cell line: 41>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# Train the classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m# Predict on the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    199\u001b[0m             )\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         sample_weight = np.asarray(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_validate_targets\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_class_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    750\u001b[0m                 \u001b[0;34m\"The number of classes has to be greater than one; got %d class\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m                 \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The number of classes has to be greater than one; got 1 class"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "import librosa\n",
        "from scipy.io import wavfile\n",
        "import joblib\n",
        "\n",
        "# Load the merged dataset\n",
        "general_data = pd.read_csv('general.csv')\n",
        "\n",
        "# Separate features and labels\n",
        "features = general_data.iloc[:, :-1]\n",
        "labels = general_data.iloc[:, -1]\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, encoded_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Select the relevant features for scaling\n",
        "selected_features = ['chroma_stft', 'spectral_centroid', 'spectral_bandwidth', 'spectral_rolloff', 'rmse', 'zero_crossing_rate']\n",
        "X_train_selected = X_train[selected_features]\n",
        "X_test_selected = X_test[selected_features]\n",
        "\n",
        "# Scale the selected features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_selected)\n",
        "X_test_scaled = scaler.transform(X_test_selected)\n",
        "\n",
        "# Train the classifier\n",
        "classifier = SVC()\n",
        "classifier.fit(X_train_scaled, y_train)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "\n",
        "# Save the classifier model and label encoder\n",
        "joblib.dump(classifier, 'classifier_model.pkl')\n",
        "joblib.dump(label_encoder, 'label_encoder.pkl')\n",
        "\n",
        "# Define a function to classify a single WAV file\n",
        "def classify_audio(file_path):\n",
        "    audio, sr = librosa.load(file_path, sr=None)  # Load the audio file\n",
        "\n",
        "    # Extract features\n",
        "    chroma_stft = librosa.feature.chroma_stft(y=audio, sr=sr)\n",
        "    spectral_centroid = librosa.feature.spectral_centroid(y=audio, sr=sr)[0]\n",
        "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=audio, sr=sr)[0]\n",
        "    spectral_rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sr)[0]\n",
        "    rmse = librosa.feature.rms(y=audio)[0]\n",
        "    zero_crossing_rate = librosa.feature.zero_crossing_rate(y=audio)[0]\n",
        "\n",
        "    # Concatenate features into a single feature vector\n",
        "    features = np.hstack(\n",
        "        (chroma_stft.T, spectral_centroid.reshape(-1, 1), spectral_bandwidth.reshape(-1, 1),\n",
        "         spectral_rolloff.reshape(-1, 1), rmse.reshape(-1, 1), zero_crossing_rate.reshape(-1, 1))\n",
        "    )\n",
        "\n",
        "    # Select the relevant features for scaling\n",
        "    selected_features = features[:, :6]\n",
        "\n",
        "    # Scale the selected features\n",
        "    scaled_features = scaler.transform(selected_features)\n",
        "\n",
        "    # Classify the audio sample\n",
        "    predicted_label = classifier.predict(scaled_features)\n",
        "\n",
        "    # Inverse transform the predicted label to get the original class name\n",
        "    predicted_class = label_encoder.inverse_transform(predicted_label)\n",
        "\n",
        "    return predicted_class[0]  # Return the predicted label as a string\n",
        "\n",
        "# Use the classify_audio function to classify a single WAV file\n",
        "wav_file_path = 'sound_444.wav'  # Replace with the path to your input WAV file\n",
        "\n",
        "predicted_label = classify_audio(wav_file_path)\n",
        "print(\"Predicted Label:\", predicted_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hc4d6VgKXN2O",
        "outputId": "a31e527a-60c1-4e6d-8aad-980a7b56de2b"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9125\n",
            "Precision: 0.9024390243902439\n",
            "Recall: 0.925\n",
            "F1 Score: 0.9135802469135802\n",
            "Predicted Label: ambulance\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "import librosa\n",
        "from scipy.io import wavfile\n",
        "import joblib\n",
        "\n",
        "# Load the merged dataset\n",
        "general_data = pd.read_csv('general.csv')\n",
        "\n",
        "# Separate features and labels\n",
        "features = general_data.iloc[:, :-1]\n",
        "labels = general_data.iloc[:, -1]\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, encoded_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the selected feature columns\n",
        "selected_features = ['chroma_stft', 'spectral_centroid', 'spectral_bandwidth', 'spectral_rolloff', 'rmse', 'zero_crossing_rate']\n",
        "\n",
        "# Extract selected features for training set\n",
        "X_train_selected = X_train[selected_features]\n",
        "\n",
        "# Extract selected features for testing set\n",
        "X_test_selected = X_test[selected_features]\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_selected)\n",
        "X_test_scaled = scaler.transform(X_test_selected)\n",
        "\n",
        "# Train the classifier\n",
        "classifier = SVC()\n",
        "classifier.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Save the classifier model and label encoder\n",
        "joblib.dump(classifier, 'classifier_model.pkl')\n",
        "joblib.dump(label_encoder, 'label_encoder.pkl')\n",
        "\n",
        "# Define a function to classify a single WAV file\n",
        "def classify_audio(file_path):\n",
        "    audio, sr = librosa.load(file_path, sr=None)  # Load the audio file\n",
        "\n",
        "    # Extract features\n",
        "    chroma_stft = librosa.feature.chroma_stft(y=audio, sr=sr)\n",
        "    spectral_centroid = librosa.feature.spectral_centroid(y=audio, sr=sr)[0]\n",
        "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=audio, sr=sr)[0]\n",
        "    spectral_rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sr)[0]\n",
        "    rmse = librosa.feature.rms(y=audio)[0]\n",
        "    zero_crossing_rate = librosa.feature.zero_crossing_rate(y=audio)[0]\n",
        "\n",
        "    # Create a feature matrix from extracted features\n",
        "    features = np.vstack([chroma_stft, spectral_centroid, spectral_bandwidth, spectral_rolloff, rmse, zero_crossing_rate]).T\n",
        "\n",
        "    # Select the relevant features for scaling\n",
        "    selected_features = features[:, :6]\n",
        "\n",
        "    # Scale the selected features\n",
        "    scaled_features = scaler.transform(selected_features)\n",
        "\n",
        "    # Classify the audio sample\n",
        "    predicted_label = classifier.predict(scaled_features)\n",
        "\n",
        "    # Inverse transform the predicted label to get the original class name\n",
        "    predicted_class = label_encoder.inverse_transform(predicted_label)\n",
        "\n",
        "    return predicted_class[2]  # Return the predicted label as a string\n",
        "\n",
        "# Use the classify_audio function to classify a single WAV file\n",
        "wav_file_path = 'sound_444.wav'  # Replace with the path to your input WAV file\n",
        "\n",
        "predicted_label = classify_audio(wav_file_path)\n",
        "print(\"Predicted Label:\", predicted_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWKvOS04ZBRZ",
        "outputId": "60b1b965-cc4e-465d-b19e-1f54d0662357"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Label: ambulance\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "import librosa\n",
        "from scipy.io import wavfile\n",
        "import joblib\n",
        "\n",
        "# Load the merged dataset\n",
        "general_data = pd.read_csv('general.csv')\n",
        "\n",
        "# Separate features and labels\n",
        "features = general_data.iloc[:, :6]\n",
        "labels = general_data.iloc[:, -1]\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Select the relevant features for scaling\n",
        "selected_features = ['chroma_stft', 'spectral_centroid', 'spectral_bandwidth', 'spectral_rolloff', 'rmse', 'zero_crossing_rate']\n",
        "selected_features_data = features[selected_features]\n",
        "\n",
        "# Scale the selected features\n",
        "scaler = StandardScaler()\n",
        "scaled_features = scaler.fit_transform(selected_features_data)\n",
        "\n",
        "# Train the classifier\n",
        "classifier = SVC()\n",
        "classifier.fit(scaled_features, encoded_labels)\n",
        "\n",
        "# Save the classifier model and label encoder\n",
        "joblib.dump(classifier, 'classifier_model.pkl')\n",
        "joblib.dump(label_encoder, 'label_encoder.pkl')\n",
        "\n",
        "# Define a function to classify a single WAV file\n",
        "def classify_audio(file_path):\n",
        "    audio, sr = librosa.load(file_path, sr=None)  # Load the audio file\n",
        "\n",
        "    # Extract features\n",
        "    chroma_stft = librosa.feature.chroma_stft(y=audio, sr=sr)\n",
        "    spectral_centroid = librosa.feature.spectral_centroid(y=audio, sr=sr)[0]\n",
        "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=audio, sr=sr)[0]\n",
        "    spectral_rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sr)[0]\n",
        "    rmse = librosa.feature.rms(y=audio)[0]\n",
        "    zero_crossing_rate = librosa.feature.zero_crossing_rate(y=audio)[0]\n",
        "\n",
        "    # Create a feature vector\n",
        "    features = np.hstack(\n",
        "        (chroma_stft.T, spectral_centroid.reshape(-1, 1), spectral_bandwidth.reshape(-1, 1),\n",
        "         spectral_rolloff.reshape(-1, 1), rmse.reshape(-1, 1), zero_crossing_rate.reshape(-1, 1))\n",
        "    )\n",
        "\n",
        "    # Select the relevant features for scaling\n",
        "    selected_features = features[:, :6]\n",
        "\n",
        "    # Scale the selected features\n",
        "    scaled_features = scaler.transform(selected_features)\n",
        "\n",
        "    # Classify the audio sample\n",
        "    predicted_label = classifier.predict(scaled_features)\n",
        "\n",
        "    # Inverse transform the predicted label to get the original class name\n",
        "    predicted_class = label_encoder.inverse_transform(predicted_label)\n",
        "\n",
        "    return predicted_class[0]  # Return the predicted label as a string\n",
        "\n",
        "# Use the classify_audio function to classify the WAV file\n",
        "wav_file_path = 'sound_403.wav'  # Replace with the path to your input WAV file\n",
        "\n",
        "predicted_label = classify_audio(wav_file_path)\n",
        "print(\"Predicted Label:\", predicted_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plFjgFWiZ03_",
        "outputId": "15dfad4f-e764-46c3-dcaa-07ce23e5e34c"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Label: ambulance\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = general_data.iloc[:, -1]"
      ],
      "metadata": {
        "id": "YzUqbz5waN68"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngJ5INgzbymf",
        "outputId": "96c43d0f-7716-46fa-9049-513674da61e4"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      ambulance\n",
              "1      ambulance\n",
              "2      ambulance\n",
              "3      ambulance\n",
              "4      ambulance\n",
              "         ...    \n",
              "395      traffic\n",
              "396      traffic\n",
              "397      traffic\n",
              "398      traffic\n",
              "399      traffic\n",
              "Name: label, Length: 400, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import librosa\n",
        "\n",
        "# Load the merged dataset\n",
        "general_data = pd.read_csv('general.csv')\n",
        "\n",
        "# Separate features and labels\n",
        "features = general_data.iloc[:, :-1]\n",
        "labels = general_data.iloc[:, -1]\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "scaled_features = scaler.fit_transform(features)\n",
        "\n",
        "# Train the classifier\n",
        "classifier = KNeighborsClassifier(n_neighbors=5)\n",
        "classifier.fit(scaled_features, encoded_labels)\n",
        "\n",
        "# Save the classifier model and label encoder\n",
        "joblib.dump(classifier, 'classifier_model.pkl')\n",
        "joblib.dump(label_encoder, 'label_encoder.pkl')\n",
        "\n",
        "# Define a function to classify a single WAV file\n",
        "def classify_audio(file_path):\n",
        "    audio, sr = librosa.load(file_path, sr=None)  # Load the audio file\n",
        "\n",
        "    # Extract features\n",
        "    chroma_stft = librosa.feature.chroma_stft(y=audio, sr=sr)\n",
        "    spectral_centroid = librosa.feature.spectral_centroid(y=audio, sr=sr)[0]\n",
        "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=audio, sr=sr)[0]\n",
        "    spectral_rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sr)[0]\n",
        "    rmse = librosa.feature.rms(y=audio)[0]\n",
        "    zero_crossing_rate = librosa.feature.zero_crossing_rate(y=audio)[0]\n",
        "\n",
        "    # Create a feature vector\n",
        "    features = np.array([chroma_stft[0][0], spectral_centroid[0], spectral_bandwidth[0],\n",
        "                         spectral_rolloff[0], rmse[0], zero_crossing_rate[0]]).reshape(1, -1)\n",
        "\n",
        "    # Scale the features\n",
        "    scaled_features = scaler.transform(features)\n",
        "\n",
        "    # Classify the audio sample\n",
        "    predicted_label = classifier.predict(scaled_features)\n",
        "\n",
        "    # Inverse transform the predicted label to get the original class name\n",
        "    predicted_class = label_encoder.inverse_transform(predicted_label)\n",
        "\n",
        "    return predicted_class[0]  # Return the predicted label as a string\n",
        "\n",
        "# Use the classify_audio function to classify the WAV file\n",
        "wav_file_path = 'sound_403.wav'  # Replace with the path to your input WAV file\n",
        "\n",
        "predicted_label = classify_audio(wav_file_path)\n",
        "print(\"Predicted Label:\", predicted_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOCRP8vPbzWF",
        "outputId": "fa462f26-8530-47b8-802f-b3eb84b8c5d3"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Label: ambulance\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
        "import librosa\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('general.csv')\n",
        "\n",
        "# Select relevant features for training\n",
        "features = data.iloc[:, :6]\n",
        "labels = data.iloc[:, -1]\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, encoded_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape the feature arrays for compatibility with CNN input\n",
        "X_train_reshaped = X_train_scaled.reshape(X_train_scaled.shape[0], X_train_scaled.shape[1], 1)\n",
        "X_test_reshaped = X_test_scaled.reshape(X_test_scaled.shape[0], X_test_scaled.shape[1], 1)\n",
        "\n",
        "# Define the CNN model\n",
        "model = Sequential()\n",
        "model.add(Conv1D(32, kernel_size=3, activation='relu', input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_reshaped, y_train, batch_size=32, epochs=10, verbose=1)\n",
        "\n",
        "# Save the trained model and label encoder\n",
        "model.save('classifier_model.h5')\n",
        "joblib.dump(label_encoder, 'label_encoder.pkl')\n",
        "\n",
        "# Define a function to classify a single WAV file\n",
        "def classify_audio(file_path):\n",
        "    audio, sr = librosa.load(file_path, sr=None)  # Load the audio file\n",
        "\n",
        "    # Extract features\n",
        "    chroma_stft = librosa.feature.chroma_stft(y=audio, sr=sr)[0]\n",
        "    spectral_centroid = librosa.feature.spectral_centroid(y=audio, sr=sr)[0]\n",
        "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=audio, sr=sr)[0]\n",
        "    spectral_rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sr)[0]\n",
        "    rmse = librosa.feature.rms(y=audio)[0]\n",
        "    zero_crossing_rate = librosa.feature.zero_crossing_rate(y=audio)[0]\n",
        "\n",
        "    # Create a feature vector\n",
        "    features = np.concatenate([chroma_stft, spectral_centroid, spectral_bandwidth,\n",
        "                         spectral_rolloff, rmse, zero_crossing_rate])\n",
        "\n",
        "    # Scale the features\n",
        "    scaled_features = scaler.transform([features[:6]])\n",
        "\n",
        "    # Reshape the feature array for compatibility with CNN input\n",
        "    reshaped_features = scaled_features.reshape(1, scaled_features.shape[1], 1)\n",
        "\n",
        "    # Classify the audio sample\n",
        "    predicted_prob = model.predict(reshaped_features)\n",
        "    predicted_label = (predicted_prob > 0.5).astype(int)\n",
        "\n",
        "    # Inverse transform the predicted label to get the original class name\n",
        "    predicted_class = label_encoder.inverse_transform(predicted_label)[0]\n",
        "\n",
        "    return predicted_class  # Return the predicted label as a string\n",
        "\n",
        "# Use the classify_audio function to classify the WAV file\n",
        "wav_file_path = 'sound_403.wav'  # Replace with the path to your input WAV file\n",
        "\n",
        "predicted_label = classify_audio(wav_file_path)\n",
        "print(\"Predicted Label:\", predicted_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LyuJwtDccIo",
        "outputId": "4227cf66-19de-4e74-a573-753871523bfe"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "10/10 [==============================] - 2s 5ms/step - loss: 0.6640 - accuracy: 0.5750\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.5883 - accuracy: 0.8000\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.5291 - accuracy: 0.9000\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.4718 - accuracy: 0.9094\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.4357 - accuracy: 0.9187\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.3881 - accuracy: 0.9219\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3347 - accuracy: 0.9281\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3192 - accuracy: 0.9219\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2722 - accuracy: 0.9375\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2530 - accuracy: 0.9406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 129ms/step\n",
            "Predicted Label: ambulance\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py:155: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from tensorflow.keras.models import load_model\n",
        "import librosa\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('general.csv')\n",
        "\n",
        "# Select relevant features for training\n",
        "features = data.iloc[:, :6]\n",
        "labels = data.iloc[:, -1]\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "scaled_features = scaler.fit_transform(features)\n",
        "\n",
        "# Load the saved model\n",
        "model = load_model('classifier_model.h5')\n",
        "\n",
        "# Define a function to preprocess the audio\n",
        "def preprocess_audio(file_path):\n",
        "    audio, sr = librosa.load(file_path, sr=None)  # Load the audio file\n",
        "\n",
        "    # Extract features\n",
        "    chroma_stft = np.mean(librosa.feature.chroma_stft(y=audio, sr=sr), axis=1)\n",
        "    spectral_centroid = np.mean(librosa.feature.spectral_centroid(y=audio, sr=sr))\n",
        "    spectral_bandwidth = np.mean(librosa.feature.spectral_bandwidth(y=audio, sr=sr))\n",
        "    spectral_rolloff = np.mean(librosa.feature.spectral_rolloff(y=audio, sr=sr))\n",
        "    rmse = np.mean(librosa.feature.rms(y=audio))\n",
        "    zero_crossing_rate = np.mean(librosa.feature.zero_crossing_rate(y=audio))\n",
        "\n",
        "    # Create a feature vector\n",
        "    features = np.array([chroma_stft, spectral_centroid, spectral_bandwidth,\n",
        "                         spectral_rolloff, rmse, zero_crossing_rate])\n",
        "\n",
        "    return features\n",
        "\n",
        "# Define a function to classify a single WAV file\n",
        "def classify_audio(file_path):\n",
        "    # Preprocess the audio\n",
        "    features = preprocess_audio(file_path)\n",
        "\n",
        "    # Scale the features\n",
        "    scaled_features = scaler.transform([features])\n",
        "\n",
        "    # Classify the audio sample\n",
        "    predicted_prob = model.predict(np.expand_dims(scaled_features, axis=2))\n",
        "    predicted_label = (predicted_prob > 0.5).astype(int)\n",
        "\n",
        "    # Inverse transform the predicted label to get the original class name\n",
        "    predicted_class = label_encoder.inverse_transform(predicted_label)[0]\n",
        "\n",
        "    return predicted_class  # Return the predicted label as a string\n",
        "\n",
        "# Use the classify_audio function to classify the WAV file\n",
        "wav_file_path = 'sound_1.wav'  # Replace with the path to your input WAV file\n",
        "\n",
        "predicted_label = classify_audio(wav_file_path)\n",
        "print(\"Predicted Label:\", predicted_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "id": "tq6rcSfSdKkJ",
        "outputId": "abbd583c-fc2a-43db-dbe7-c0d086995893"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-127-c39ee26535e1>:38: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  features = np.array([chroma_stft, spectral_centroid, spectral_bandwidth,\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-127-c39ee26535e1>\u001b[0m in \u001b[0;36m<cell line: 63>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0mwav_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'sound_1.wav'\u001b[0m  \u001b[0;31m# Replace with the path to your input WAV file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0mpredicted_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassify_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predicted Label:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-127-c39ee26535e1>\u001b[0m in \u001b[0;36mclassify_audio\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m# Scale the features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mscaled_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;31m# Classify the audio sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m    990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m         \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 992\u001b[0;31m         X = self._validate_data(\n\u001b[0m\u001b[1;32m    993\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m             \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    877\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m                 raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"numpy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"numpy.array_api\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;31m# Use NumPy API to support order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7sWg0E_ef3D5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}